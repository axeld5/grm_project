{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import MessagePassing, global_add_pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important elements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-trained word embedding model\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This movie is another Christian propaganda fil...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A woman who hates cats (Alice Krige) and her s...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beast Wars is a show that is over-hyped, overp...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An excellent example of \"cowboy noir\", as it's...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ok, basically this is a popcorn sci-fi movie, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  This movie is another Christian propaganda fil...    0.0\n",
       "1  A woman who hates cats (Alice Krige) and her s...    1.0\n",
       "2  Beast Wars is a show that is over-hyped, overp...    0.0\n",
       "3  An excellent example of \"cowboy noir\", as it's...    1.0\n",
       "4  Ok, basically this is a popcorn sci-fi movie, ...    1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df = df.sample(frac=1, random_state = 42).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_review(review, label, graph_visu=False):\n",
    "\n",
    "    ## preprocess of sentences to have a graph that \"sees\" sentences \n",
    "\n",
    "    doc = nlp(review)\n",
    "    sentences = [sent for sent in doc.sents]\n",
    "\n",
    "    sentences = [[token.text for token in sent] for sent in sentences]\n",
    "    sentences = [[word for word in sent if word.isalpha()] for sent in sentences]\n",
    "    sentences = [[word for word in sent if not nlp.vocab[word].is_stop] for sent in sentences]\n",
    "\n",
    "\n",
    "    sentences = [sent for sent in sentences if len(sent) > 0]\n",
    "\n",
    "    dico_words = {}\n",
    "    for i,sent in enumerate(sentences):\n",
    "        for word in sent:\n",
    "            if word not in dico_words:\n",
    "                dico_words[word] = [i]\n",
    "            else:\n",
    "                dico_words[word] += [i]\n",
    "\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(dico_words.keys())\n",
    "\n",
    "    # print(sentences)\n",
    "    ## Linking sentences in the graph \n",
    "    for i in range(len(sentences)-1):\n",
    "        previous_word = sentences[i][-1]\n",
    "        next_word = sentences[i+1][0]\n",
    "        if previous_word != next_word:\n",
    "            G.add_edge(previous_word, next_word, weight = 1)\n",
    "\n",
    "    for word in dico_words.keys():\n",
    "        for word2 in dico_words.keys():\n",
    "            if word != word2:\n",
    "                common_sentences = set(dico_words[word]).intersection(set(dico_words[word2]))\n",
    "                if len(common_sentences) > 0:\n",
    "                    G.add_edge(word, word2, weight = 1+len(common_sentences))\n",
    "\n",
    "    if graph_visu:\n",
    "        plt.figure(figsize=(10,10))\n",
    "        nx.draw(G, with_labels=True, font_weight='bold')\n",
    "        plt.show()\n",
    "\n",
    "    # For the GNN : \n",
    "    # nodes \n",
    "    node_features = []\n",
    "    for node in G.nodes():\n",
    "        node_features.append(nlp.vocab[node].vector)\n",
    "    node_features = np.array(node_features)\n",
    "    # edges\n",
    "    edges = []\n",
    "    for edge in G.edges():\n",
    "        edges.append([list(G.nodes()).index(edge[0]), list(G.nodes()).index(edge[1])])\n",
    "    edges = np.array(edges)\n",
    "    # label\n",
    "    label = [int(label)]\n",
    "\n",
    "\n",
    "    # Create a PyTorch Geometric Data object\n",
    "    x = torch.tensor(node_features, dtype=torch.float)\n",
    "    edge_index = torch.tensor(edges.T, dtype=torch.long)\n",
    "    y = torch.tensor(label, dtype=torch.float)\n",
    "    data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get only 200 reviews \n",
    "list_of_reviews = [] \n",
    "\n",
    "for i in range(200):\n",
    "    data = preprocess_review(df['review'][i], df['label'][i])\n",
    "    list_of_reviews.append(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[57, 300], edge_index=[2, 228], y=[1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_reviews[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the data into training and test sets \n",
    "# ( Yes I know that I am doing it on the 200 reviews of the training file but it was just a small test to make sure that the graphs were compatible ) \n",
    "train_data, test_data = train_test_split(list_of_reviews, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive reviews in the training set: 74\n",
      "Number of negative reviews in the training set: 86\n"
     ]
    }
   ],
   "source": [
    "### Is the data balanced ?\n",
    "\n",
    "def get_num_pos_neg(data):\n",
    "    labels = [d.y.item() for d in data]\n",
    "    pos = labels.count(1)\n",
    "    neg = labels.count(0)\n",
    "\n",
    "    return pos, neg\n",
    "\n",
    "pos,neg = get_num_pos_neg(train_data)\n",
    "\n",
    "print(f'Number of positive reviews in the training set: {pos}')\n",
    "print(f'Number of negative reviews in the training set: {neg}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 92.8282, Train Acc: 0.7125 Test Acc: 0.6000\n",
      "Epoch: 002, Loss: 34.5446, Train Acc: 0.5938 Test Acc: 0.5500\n",
      "Epoch: 003, Loss: 66.2533, Train Acc: 0.5188 Test Acc: 0.5500\n",
      "Epoch: 004, Loss: 27.8972, Train Acc: 0.8000 Test Acc: 0.5500\n",
      "Epoch: 005, Loss: 39.8170, Train Acc: 0.8313 Test Acc: 0.6000\n",
      "Epoch: 006, Loss: 14.9998, Train Acc: 0.9000 Test Acc: 0.5750\n",
      "Epoch: 007, Loss: 32.1674, Train Acc: 0.8875 Test Acc: 0.5500\n",
      "Epoch: 008, Loss: 2.7835, Train Acc: 0.9062 Test Acc: 0.6000\n",
      "Epoch: 009, Loss: 4.5466, Train Acc: 0.9375 Test Acc: 0.6250\n",
      "Epoch: 010, Loss: 10.0300, Train Acc: 0.9187 Test Acc: 0.6250\n",
      "Epoch: 011, Loss: 6.2774, Train Acc: 0.9688 Test Acc: 0.6750\n",
      "Epoch: 012, Loss: 0.2388, Train Acc: 0.9875 Test Acc: 0.6750\n",
      "Epoch: 013, Loss: 0.1808, Train Acc: 0.9875 Test Acc: 0.6500\n",
      "Epoch: 014, Loss: 0.1165, Train Acc: 0.9875 Test Acc: 0.7000\n",
      "Epoch: 015, Loss: 0.1542, Train Acc: 1.0000 Test Acc: 0.7250\n",
      "Epoch: 016, Loss: 0.0107, Train Acc: 0.9750 Test Acc: 0.6500\n",
      "Epoch: 017, Loss: 0.1867, Train Acc: 1.0000 Test Acc: 0.7000\n",
      "Epoch: 018, Loss: 1.4746, Train Acc: 0.9062 Test Acc: 0.7250\n",
      "Epoch: 019, Loss: 7.5491, Train Acc: 0.9688 Test Acc: 0.6500\n",
      "Epoch: 020, Loss: 1.8366, Train Acc: 0.9375 Test Acc: 0.6000\n",
      "Epoch: 021, Loss: 45.2433, Train Acc: 0.9000 Test Acc: 0.6500\n",
      "Epoch: 022, Loss: 41.3655, Train Acc: 0.8938 Test Acc: 0.6500\n",
      "Epoch: 023, Loss: 21.6132, Train Acc: 0.8313 Test Acc: 0.5500\n",
      "Epoch: 024, Loss: 7.1529, Train Acc: 0.9563 Test Acc: 0.7250\n",
      "Epoch: 025, Loss: 8.9310, Train Acc: 0.9875 Test Acc: 0.7000\n",
      "Epoch: 026, Loss: 0.7509, Train Acc: 1.0000 Test Acc: 0.7250\n",
      "Epoch: 027, Loss: 0.0000, Train Acc: 1.0000 Test Acc: 0.7250\n",
      "Epoch: 028, Loss: 0.0000, Train Acc: 1.0000 Test Acc: 0.7250\n",
      "Epoch: 029, Loss: 0.0000, Train Acc: 1.0000 Test Acc: 0.7250\n"
     ]
    }
   ],
   "source": [
    "### This model is juste an exemple to test the graphs\n",
    "class GraphNet(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GraphNet, self).__init__(aggr=\"add\")\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.lin(x)\n",
    "        return self.propagate(edge_index, x=x)\n",
    "\n",
    "    def message(self, x_j):\n",
    "        return x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out\n",
    "\n",
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.conv1 = GraphNet(in_channels, hidden_channels)\n",
    "        self.conv2 = GraphNet(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = global_add_pool(x, torch.zeros(x.size(0), dtype=torch.long))\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define the model and optimizer\n",
    "model = Classifier(300, 128, 2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Define the training loop\n",
    "def train(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x.float(), data.edge_index)\n",
    "        loss = F.nll_loss(out, data.y.long())\n",
    "        loss.backward()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "        optimizer.step()\n",
    "    return total_loss / len(loader.dataset)\n",
    "    \n",
    "    \n",
    "# Define the testing loop\n",
    "def test(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x.float(), data.edge_index)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += pred.eq(data.y.long()).sum().item()\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader = DataLoader(train_data, batch_size=1 , shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=1 , shuffle=False)\n",
    "for epoch in range(1, 30):\n",
    "    loss = train(model, train_loader, optimizer, device)\n",
    "    train_acc = test(model, train_loader, device)\n",
    "    test_acc = test(model, test_loader, device)\n",
    "    print(f\"Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}\", f\"Test Acc: {test_acc:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1373f02ec55a1d27e5234d98ea75429aa3028e3b067e6f9b4a057c00b3c2d09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
